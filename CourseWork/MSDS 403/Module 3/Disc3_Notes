Autonomous vehicles
- sensor data
- actuator data

Autonomous cars create and maintain a map of their surroundings based on a variety of sensors situated in different parts of the vehicle. 
- Radar sensors monitor the position of nearby vehicles
- video cameras detect traffic lights, read road signs, track other vehicles, and look for pedestrians.
- Lidar (light detection and ranging): pulse and bounce light off the car's surroundings to measure distances, detect road edges, and identify lane markings.
- Ultrasonic sensors in the wheels detect curbs and other vehicles when parking.

Sophisticated software then processes all this sensory input, plots a path, and sends instructions to the car's actuators, which control acceleration, braking, and steering. Hard-coded rules, obstacle avoidance algorithms, predictive modeling, and object recognition help the software follow traffic rules and navigate obstacles. 

Challenges with AV:

Lidar and Radar:

Weather conditions:


Transportation Route Optimization
- Similar to Waze: Crowd sourced, real-time information that translates into traffic conditions and road structure. Operator/Driver reporting. 
- Wave collects...? Data from the app? What data?
- Collects GPS data, car speed, direction, user input data, etc. duration of travel, road congestion, obstacles, - more structured data (relational databases)

	- calculates average speed, errors, improve road layout, learn road and turn direction, etc. 
https://support.google.com/waze/answer/6078702?hl=en 
- Weather data: Unstructured data - Satellite images, radar and sonar data, social media data, data lakes. 
https://www.dummies.com/programming/big-data/engineering/unstructured-data-in-a-big-data-environment/